<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>README</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      .smallcaps{font-variant: small-caps;}
      .line-block{white-space: pre-line;}
      .column{display: inline-block;}
  </style>
  <link rel="stylesheet" href="/Users/fabs/diary/bin/github-pandoc.css">
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h1 id="cubismz-a-parallel-data-compression-framework-for-large-scale-3d-scientific-data">CubismZ: A Parallel Data Compression Framework for Large Scale 3D Scientific Data</h1>
<h2 id="design">Design</h2>
<p>CubismZ performs two compression stages on the input dataset. The first stage makes use of (lossy) floating point compression algorithms. In the second stage, general-purpose lossless methods are applied to the compressed data of the first stage. A more detailed description can be found in the paper.</p>
<h4 id="substage-1-floating-point-compression">Substage 1: Floating point compression</h4>
<p>Available compressors for this stage are:</p>
<ul>
<li>3D wavelets (<a href="http://www.cse-lab.ethz.ch" title="http://www.cse-lab.ethz.ch">CSELAB</a>)</li>
<li>FPZIP (<a href="https://computation.llnl.gov/projects/floating-point-compression" title="https://computation.llnl.gov/projects/floating-point-compression">LLNL</a>)</li>
<li>ZFP (<a href="https://computation.llnl.gov/projects/floating-point-compression" title="https://computation.llnl.gov/projects/floating-point-compression">LLNL</a>)</li>
<li>SZ (<a href="https://collab.cels.anl.gov/display/ESR/SZ" title="https://collab.cels.anl.gov/display/ESR/SZ">ANL</a>)</li>
</ul>
<h4 id="substage-2-general-purpose-lossless-compression">Substage 2: General-purpose lossless compression</h4>
<p>Available compression techniques for this stage are:</p>
<ul>
<li><a href="https://zlib.net/" title="https://zlib.net/">ZLIB</a></li>
<li><a href="https://lz4.github.io/lz4/" title="https://lz4.github.io/lz4/">LZ4</a></li>
</ul>
<p>Before lossless compression, data (byte) shuffling and bit zeroing can be optionally applied to the output of the wavelet-based compression scheme.</p>
<h2 id="compilation">Compilation</h2>
<h4 id="external-software-dependencies">External software dependencies</h4>
<ul>
<li>MPI library (Tested platforms: MPICH, OpenMPI, MVAPICH2)</li>
<li>Parallel HDF5 (Compatible with one of the above MPI libraries)<br />
</li>
<li>ZLIB compression library</li>
</ul>
<h4 id="configured-compilation">Configured compilation</h4>
<p>The default set of executables required to reproduce the included test cases can be generated by invoking <code>make</code> in the root directory.</p>
<p>The <code>C++</code> and <code>C</code> MPI wrappers can be set using the <code>MPICC</code> and <code>mpicc</code> flags, respectively. They default to <code>MPICC=mpic++</code> and <code>mpicc=mpicc</code>.</p>
<p>The software has been tested with the <a href="https://gcc.gnu.org/" title="https://gcc.gnu.org/">GCC</a>, <a href="https://software.intel.com/en-us/c-compilers" title="https://software.intel.com/en-us/c-compilers">Intel</a> and <a href="http://www.llvm.org/" title="http://www.llvm.org/">Clang</a> compilers.</p>
<p>OpenMP is enabled by default, except for the Clang compiler. It can be enabled for a Clang installation that supports OpenMP by passing <code>extra=-fopenmp</code> to the <code>make</code> command.</p>
<p>In order to compile the software, a parallel build of the <a href="http://www.hdfgroup.org">HDF5</a> library is required. The path to the HDF5 <code>include</code> and <code>lib</code> directories can be specified using the <code>hdf-incdir</code> and <code>hdf-libdir</code> variables respectively. See the <a href="./Makefile">Makefile</a> for further details.</p>
<p>Successful execution of the build chain generates a set of executables in the <code>./Tools/bin</code> directory. The configuration for these binaries is as follows:</p>
<h5 id="no-compression-default">No compression (default)</h5>
<p>Conversion to the CZ format without data compression. No special flags are required for this build at compile time. This target can be built individually inside the <code>Tools</code> directory with:</p>
<pre><code>make</code></pre>
<h5 id="wavelets-and-zlib">Wavelets and ZLIB</h5>
<p>Generates a build using the CubismZ wavelet compression scheme for the first compression stage (floating point compression) and applies <a href="https://zlib.net/" title="https://zlib.net/">ZLIB</a> in the second compression stage. This target can be built individually inside the <code>Tools</code> directory with:</p>
<pre><code>make wavz=1 zlib=1</code></pre>
<h5 id="zfp">ZFP</h5>
<p>Generates a build using the <a href="https://computation.llnl.gov/projects/floating-point-compression" title="https://computation.llnl.gov/projects/floating-point-compression">ZFP</a> floating point compressor for the first compression stage. No further compression is applied for the second stage. This target can be built individually inside the <code>Tools</code> directory with:</p>
<pre><code>make zfp=1</code></pre>
<h5 id="fpzip">FPZIP</h5>
<p>Generates a build using the <a href="https://computation.llnl.gov/projects/floating-point-compression" title="https://computation.llnl.gov/projects/floating-point-compression">FPZIP</a> floating point compressor for the first compression stage. No further compression is applied for the second stage. This target can be built individually inside the <code>Tools</code> directory with:</p>
<pre><code>make fpzip=1</code></pre>
<h5 id="sz">SZ</h5>
<p>Generates a build using the <a href="https://collab.cels.anl.gov/display/ESR/SZ" title="https://collab.cels.anl.gov/display/ESR/SZ">SZ</a> floating point compressor for the first compression stage. No further compression is applied for the second stage. This target can be built individually inside the <code>Tools</code> directory with:</p>
<pre><code>make sz=1</code></pre>
<h4 id="custom-compilation">Custom compilation</h4>
<p>Custom user defined configurations are possible as well. Any of the combinations described in the <a href="#design">design</a> section are possible. Custom builds require that the <code>ThirdParty</code> dependencies are compiled first. In order to do so, the command</p>
<pre><code>make thirdparty-libs</code></pre>
<p>must be executed from the <em>root directory</em>. Custom builds can then be generated by using the <code>Tools/Makefile</code>. Assuming the working directory is <code>Tools</code>, example custom builds can be generated with:</p>
<h5 id="wavelets-shuffling-and-zlib">Wavelets, shuffling and ZLIB</h5>
<pre><code>make install dir=mycustom1 wavz=1 shuffle3=1 zlib=1</code></pre>
<h5 id="wavelets-and-lz4">Wavelets and LZ4</h5>
<pre><code>make install dir=mycustom2 wavz=1 lz4=1</code></pre>
<p>Additional compile time flags may be required for compiler specification and HDF5 library paths. See the <a href="#configured-compilation">configured compilation</a> section for more details.</p>
<h4 id="blocksize">Blocksize</h4>
<p>The block dimension can be specified at compile time. The default value is <code>blocksize=32</code>, which translates to cubic blocks with <code>32 * 32 * 32</code> data elements. The <code>blocksize</code> argument can be passed to the make command. Its value must be a power of two.</p>
<h2 id="runtime-arguments-of-cubismz-tools-for-hdf5-datasets">Runtime arguments of CubismZ tools for HDF5 datasets:</h2>
<h4 id="the-hdf2cz-tool">The <code>hdf2cz</code> tool</h4>
<p>Compression of HDF5 files to CZ format.</p>
<pre><code>hdf2cz -bpdx &lt;nbx&gt; -bpdy &lt;nby&gt; -bpdz &lt;nbz&gt; -h5file &lt;hdf5 file&gt; -czfile &lt;cz file&gt; -threshold &lt;e&gt; [-wtype &lt;wt&gt;]</code></pre>
<ul>
<li>The HDF5 file consists of <code>nbx * nby * nbz</code> 3D blocks</li>
<li>The input HDF5 file is compressed and stored to <code>&lt;cz file&gt;</code></li>
<li>The threshold specifies how lossy the compression will be TODO: need to specify the range of threshold (?)</li>
<li>The wavelet type can optionally be specified using the <code>-wtype</code> option. The following options / wavelet types are supported
<ul>
<li>1: 4th order average interpolating wavelets</li>
<li>2: 4th order lifted interpolating wavelets</li>
<li>3: 3rd order average interpolating wavelets (default)</li>
</ul></li>
</ul>
<h4 id="the-ch2hdf-tool">The <code>ch2hdf</code> tool</h4>
<p>Decompression of CZ files and conversion to HDF5 format</p>
<pre><code>cz2hdf -czfile &lt;cz file&gt; -h5file &lt;h5 file&gt; [-wtype &lt;wt&gt;]</code></pre>
<ul>
<li>The output file can be visualized with ParaView</li>
<li>Compile time options (<code>blocksize</code>, compression scheme) must agree with those used for the compression phase. See the <a href="#blocksize">blocksize</a> section for more information.</li>
<li>The optional parameter specified by <code>wtype</code> must agree with the type of wavelets used in the compressed file.</li>
</ul>
<h4 id="the-cz2diff-tool">The <code>cz2diff</code> tool</h4>
<p>Decompress and compare two CZ files</p>
<pre><code>cz2diff -czfile1 &lt;cz file1&gt; [-wtype &lt;wt&gt;] -czfile2 &lt;cz reference file2&gt;</code></pre>
<ul>
<li>The second CZ file is used as the reference dataset and must have been generated by the default configuration of the <code>hdf2cz</code> tool, i.e., without any <a href="#no-compression-default">compression method enabled</a></li>
<li>Useful for quality assessment of the compression</li>
</ul>
<h2 id="example-fluid-dynamics-data">Example: Fluid dynamics data</h2>
<h4 id="dataset">Dataset</h4>
<p>The software release includes a set of basic tests to demonstrate the capabilities of the CubismZ compression techniques. The test data consists of the 3D pressure field of a cloud cavitation collapse simulation. The initial configuration is composed of 70 air bubbles (dispersed phase, non-condensible gas) submerged in liquid water (continuous phase) and is discretized in a cubic domain with <code>512 * 512 * 512</code> cells. Note that the simulation is under-resolved. Nevertheless, the degree of variation in the quantity of interest (3D pressure field) is sufficient to test the compression algorithms. The snapshot of the test data is taken at iteration 5000. A visualization of the gas volume fraction as well as the pressure in a plane through the cloud center for this iteration is shown below.</p>
<p><img src=".images/pressure_alpha2_5000.png" /></p>
<p>Additionally, the mean pressure over all iteration steps is shown in the next figure. Plus/minus one standard deviation is indicated by the shaded region.</p>
<p><img src=".images/mean_pressure.png" /></p>
<p>The pressure test data at iteration 5000 can be downloaded at the following link (287MB):</p>
<p><a href="https://polybox.ethz.ch/index.php/s/a3454aSFG5qDe9a/download" title="https://polybox.ethz.ch/index.php/s/a3454aSFG5qDe9a/download">data_005000.tar</a></p>
<h4 id="compression-performance-tests">Compression performance tests</h4>
<p>The compression performance tests are located in <code>Tests/Test1</code>. The test scripts require that the simulation HDF5 data <code>data_005000-p.h5</code> has been <a href="https://polybox.ethz.ch/index.php/s/a3454aSFG5qDe9a/download" title="https://polybox.ethz.ch/index.php/s/a3454aSFG5qDe9a/download">downloaded</a> and is located in the <code>Tests/Data</code> directory. The complete test chain can be run by executing <code>Tests/Test1/run_all.sh</code>. The script requires that the <a href="#configured-compilation">configured compilation</a> has been performed previously. The <code>run_all.sh</code> script generates a <code>run_all.txt</code> file with the output of the compressor test configurations. The script can be run with the syntax:</p>
<pre><code>./run_all.sh [&lt;n processors&gt;]</code></pre>
<p>where <code>&lt;n processors&gt;</code> is the number of MPI processes to be used. The default is 1. Reference output from <a href="http://www.cse-lab.ethz.ch" title="http://www.cse-lab.ethz.ch">CSELAB</a> can be found in <code>cselab_ref_run_all.txt</code>. The script executes the following tasks:</p>
<ol type="1">
<li><p><code>genref.sh</code>: Generates a reference CZ file without compression, based on the HDF5 input data. The script can also be executed individually with the syntax:</p>
<pre><code>./genref.sh</code></pre></li>
<li><p><code>test_wavz.sh</code>: Runs the <a href="#wavelets-and-zlib">wavelets and zlib</a> compressor. If no reference file exists, the script will generate it automatically. The test can be run individually with the syntax:</p>
<pre><code>./test_wavz.sh [&lt;n processors&gt; [&lt;error threshold&gt;]]</code></pre>
<p>Parameter in square brackets are optional. <code>&lt;n processors&gt;</code> sets the number of MPI processes. Defaults to 1 if not specified. The <code>&lt;error threshold&gt;</code> parameter is specific to the wavelet compressor. The default is 0.01.</p></li>
<li><p><code>test_zfp.sh</code>: Runs the <a href="#zfp">ZFP</a> compressor. If no reference file exists, the script will generate it automatically. The test can be run individually with the syntax:</p>
<pre><code>./test_zfp.sh [&lt;n processors&gt; [&lt;error threshold&gt;]]</code></pre>
<p>Parameter in square brackets are optional. <code>&lt;n processors&gt;</code> sets the number of MPI processes. Defaults to 1 if not specified. The <code>&lt;error threshold&gt;</code> parameter is specific to the ZFP compressor. The default is 0.5.</p></li>
<li><p><code>test_fpzip.sh</code>: Runs the <a href="#fpzip">FPZIP</a> compressor. If no reference file exists, the script will generate it automatically. The test can be run individually with the syntax:</p>
<pre><code>./test_fpzip.sh [&lt;n processors&gt; [&lt;n bits&gt;]]</code></pre>
<p>Parameter in square brackets are optional. <code>&lt;n processors&gt;</code> sets the number of MPI processes. Defaults to 1 if not specified. The <code>&lt;n bits&gt;</code> parameter is specific to the FPZIP compressor. The default is 22.</p></li>
<li><p><code>test_sz.sh</code>: Runs the <a href="#sz">SZ</a> compressor. If no reference file exists, the script will generate it automatically. The test can be run individually with the syntax:</p>
<pre><code>./test_sz.sh [&lt;n processors&gt; [&lt;error threshold&gt;]]</code></pre>
<p>Parameter in square brackets are optional. <code>&lt;n processors&gt;</code> sets the number of MPI processes. Defaults to 1 if not specified. The <code>&lt;error threshold&gt;</code> parameter is specific to the SZ compressor. The default is 0.01. The SZ compressor can be further configured using the provided <code>Tests/Test1/sz.config</code> file.</p></li>
</ol>
<p>The performance metrics (compression ratio, errors, PSNR value) are written to the standard output or into the file <code>run_all.txt</code> if the batch script is used. The PSNR value is computed based on the reference CZ file generated with the <code>genref.sh</code> script.</p>
<h5 id="testing-custom-builds">Testing custom builds</h5>
<p>Custom builds can be tested against the reference using the <code>test_custom.sh</code> script. The execution syntax for this script is:</p>
<pre><code>./test_custom.sh &lt;path to binaries&gt; &lt;error threshold&gt; [&lt;n processors&gt;]</code></pre>
<p>where</p>
<ul>
<li><p><code>&lt;path to binaries&gt;</code>: Path to the directory that contains the custom build. For example, if <code>dir=mycustom</code> has been passed to the <code>make</code> command, the path is <code>../../Tools/bin/mycustom</code> (assuming the current working directory is <code>Tests/Test1</code>.</p></li>
<li><p><code>&lt;error threshold&gt;</code>: Error threshold that corresponds to the chosen floating point compressor (substage1 compressor).</p></li>
<li><p><code>&lt;n processors&gt;</code>: Number of MPI processes to be used. Optional, defaults to 1.</p></li>
</ul>
<h4 id="visual-assessment-for-lossy-compressors">Visual assessment for lossy compressors</h4>
<p>An example of compression and decompression cycle is provided in <code>Tests/Test2</code>. The <code>run_all.sh</code> script can be executed to run the test chain. The script can be run with the syntax:</p>
<pre><code>./run_all.sh [&lt;n processors&gt;]</code></pre>
<p>where <code>&lt;n processors&gt;</code> is the number of MPI processes to be used. The default is 1. The input HDF5 data is compressed to the CZ format using the <code>hdf2cz</code> tool with wavelets and ZLIB compression substages. The compressed data is then converted back to HDF5 using the <code>cz2hdf</code> tool and can be used for visualization using a capable tool such as ParaView, for example.</p>
<h2 id="quick-testing">Quick Testing</h2>
<h4 id="configure">Configure</h4>
<ul>
<li>Edit <code>CubismZ/Makefile</code> and set the following options
<ul>
<li><code>MPI_CC</code>, <code>mpicc</code>: MPI-aware compiler</li>
<li><code>hdf-incdir</code>, <code>hdf-libdir</code>: location of the parallel HDF5 library</li>
</ul></li>
</ul>
<h4 id="compile">Compile</h4>
<ul>
<li>Issue <code>make</code>. This will
<ul>
<li>configure and build the third-party libraries and install them in Thirdpart/build directory.</li>
<li>build the CubismZ tools (hdf2cz, cz2hdf, cz2diff) for each of the basic configurations and put the executable into the corresponding subdirectories of the <code>CubimZ/Tools/build</code> directory.</li>
</ul></li>
</ul>
<h4 id="download-the-example-dataset">Download the example dataset</h4>
<h4 id="run-the-tests">Run the tests</h4>
</body>
</html>
